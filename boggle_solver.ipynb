{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b09f8f9",
   "metadata": {},
   "source": [
    "**Links:**\n",
    "* Wikipedia: https://en.wikipedia.org/wiki/Boggle\n",
    "* How to play? https://www.wikihow.com/Play-Boggle\n",
    "* English dice configuration: https://boardgames.stackexchange.com/questions/29264/boggle-what-is-the-dice-configuration-for-boggle-in-various-languages\n",
    "* More configurations: https://en.wikipedia.org/wiki/Talk%3aBoggle#Boggle_Variants\n",
    "* Inspiration for solver [1]: https://medium.com/@ashalabi13/solving-boggle-using-depth-first-searches-and-prefix-trees-9c3faa89ea99\n",
    "* [2] https://www.geeksforgeeks.org/boggle-find-possible-words-board-characters/\n",
    "* PyDictionary: https://pypi.org/project/english-words/\n",
    "* English words list: https://github.com/dwyl/english-words\n",
    "* Estonian word lists (based on dictionaries): https://www.eki.ee/tarkvara/wordlist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "813e56cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a39fa6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find every possible affix with a length of 2\n",
    "def find_affixes(dictionary):\n",
    "    affixes = dict()\n",
    "    for word in dictionary.keys():\n",
    "        for n in range(len(word)):\n",
    "            if n < len(word)-1:\n",
    "                affixes[word[n]+word[n+1]] = 1\n",
    "    return affixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5c890b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_chars(word):\n",
    "    # Remove words containing these characters from the dictionary\n",
    "    chars = ['ž','c','z','y','w','q','x','é','è','ê','α']\n",
    "    for char in word.lower():\n",
    "        if char in chars:\n",
    "            return False\n",
    "    if word.isalpha():\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2fda5df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary(filename):\n",
    "    if '.txt' in filename:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            words_list = f.read().splitlines()\n",
    "        words = {word.lower():1 for word in words_list if check_chars(word)}\n",
    "    elif '.json' in filename:\n",
    "        with open(filename) as json_file:\n",
    "            words_raw = json.load(json_file)\n",
    "        words = {word:1 for word in words_raw if word.isalpha()}\n",
    "            \n",
    "    # If word has a length of 3, add a value to prefix tree to indicate it\n",
    "    # Create a prefix tree\n",
    "    prefix_tree = dict()\n",
    "    for k in list(words.keys()):\n",
    "        # Prefix is also a word\n",
    "        if len(k) == 3:\n",
    "            prefix_tree[k] = 1\n",
    "        # Prefix itself isn't a word\n",
    "        elif len(k) > 3:\n",
    "            prefix_tree[k[0:3]] = 0\n",
    "        # Remove words smaller than length of 3\n",
    "        elif len(k) < 3:\n",
    "            del words[k]\n",
    "    return words, prefix_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3f40e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random board with given dice\n",
    "def create_board(dice):\n",
    "    unused_dice = dice.copy()\n",
    "    board = [list(zeros) for zeros in np.zeros((4,4))]\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            # Take a random die from the set of dice\n",
    "            die = unused_dice.pop(np.random.randint(len(unused_dice)))\n",
    "            # Assign a random letter from the die onto the board\n",
    "            board[i][j] = die[np.random.randint(6)]\n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "04fe8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get adjacent vertices for given vertex\n",
    "def get_adj(i,j):\n",
    "    adj_indices = [(i-1,j), (i+1,j), (i,j-1), (i,j+1), (i-1,j-1), (i+1,j-1), (i-1,j+1), (i+1,j+1)]\n",
    "    return list(filter(lambda x : x[0] in range(0,4) and x[1] in range(0,4), adj_indices))\n",
    "\n",
    "# For quick access save adjacent vertices into a map\n",
    "adj_map = dict()\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        adj_map[(i,j)] = get_adj(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "18a1d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth-First Search from lecture slides\n",
    "def DFS(vertices, edges, prefix_tree, affix_tree, dictionary):\n",
    "    un_visited_vertices = [[False for j in range(4)] for i in range(4)]\n",
    "    #un_visited_vertices = [(i,j) for i in range(4) for j in range(4)]\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            string = \"\"#vertices[i][j]\n",
    "            visited_vertices = [i[:] for i in un_visited_vertices]\n",
    "            #print(\"starting from\", vertices[i][j], \"at\", (i,j))\n",
    "            DFS_visit((i,j), vertices, edges, visited_vertices, string, prefix_tree, affix_tree, dictionary)\n",
    "            \n",
    "def DFS_visit(vertice, vertices, edges, visited_vertices, string, prefix_tree, affix_tree, dictionary):\n",
    "    #global comparisons\n",
    "    #global all_comparisons\n",
    "    string += vertices[vertice[0]][vertice[1]]\n",
    "    #print(string.lower())\n",
    "    visited_vertices[vertice[0]][vertice[1]] = True\n",
    "    if affix_tree != None:\n",
    "        if len(string) > 1:\n",
    "            affix = string[len(string)-2].lower()+string[len(string)-1].lower()\n",
    "            #print(affix)\n",
    "            if affix_tree.get(affix) == None:\n",
    "                return\n",
    "    else:\n",
    "        if len(string) == 3:\n",
    "            if prefix_tree.get(string.lower()) == None:\n",
    "                return\n",
    "    if dictionary.get(string.lower()) != None:\n",
    "        print(string)\n",
    "    # Find adjacent vertices\n",
    "    adj = edges[vertice]\n",
    "    for adj_v in adj:\n",
    "        if visited_vertices[adj_v[0]][adj_v[1]] == False:\n",
    "            branch_visited_vertices = [i[:] for i in visited_vertices]\n",
    "            DFS_visit(adj_v, vertices, edges, branch_visited_vertices, string, prefix_tree, affix_tree, dictionary)\n",
    "    # Backtrack\n",
    "    string = string.rstrip(string[-1])\n",
    "    visited_vertices[vertice[0]][vertice[1]] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0ac8aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en: https://boardgames.stackexchange.com/questions/29264/boggle-what-is-the-dice-configuration-for-boggle-in-various-languages\n",
    "dice = [[\"R\", \"I\", \"F\", \"O\", \"B\", \"X\"],\n",
    "       [\"I\", \"F\", \"E\", \"H\", \"E\", \"Y\"],\n",
    "       [\"D\", \"E\", \"N\", \"O\", \"W\", \"S\"],\n",
    "       [\"U\", \"T\", \"O\", \"K\", \"N\", \"D\"],\n",
    "       [\"H\", \"M\", \"S\", \"R\", \"A\", \"O\"],\n",
    "       [\"L\", \"U\", \"P\", \"E\", \"T\", \"S\"],\n",
    "       [\"A\", \"C\", \"I\", \"T\", \"O\", \"A\"],\n",
    "       [\"Y\", \"L\", \"G\", \"K\", \"U\", \"E\"],\n",
    "       [\"Qu\", \"B\", \"M\", \"J\", \"O\", \"A\"],\n",
    "       [\"E\", \"H\", \"I\", \"S\", \"P\", \"N\"],\n",
    "       [\"V\", \"E\", \"T\", \"I\", \"G\", \"N\"],\n",
    "       [\"B\", \"A\", \"L\", \"I\", \"Y\", \"T\"],\n",
    "       [\"E\", \"Z\", \"A\", \"V\", \"N\", \"D\"],\n",
    "       [\"R\", \"A\", \"L\", \"E\", \"S\", \"C\"],\n",
    "       [\"U\", \"W\", \"I\", \"L\", \"R\", \"G\"],\n",
    "       [\"P\", \"A\", \"C\", \"E\", \"M\", \"D\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2b832e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "TOE\n",
      "SHE\n",
      "BOGGLE\n",
      "HIS\n",
      "JOE\n",
      "JOSH\n",
      "HIS\n",
      "SHE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['T', 'E', 'S', 'T'],\n",
       " ['B', 'O', 'H', 'L'],\n",
       " ['G', 'J', 'I', 'H'],\n",
       " ['G', 'L', 'E', 'S']]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEST BLOCK ###\n",
    "\n",
    "dictionary = {\"test\":\"\", \"boggle\":\"\", \"his\":\"\", \"josh\":\"\", \"toe\":\"\", \"joe\":\"\", \"she\":\"\"}\n",
    "prefix_tree = {\"tes\": \"test\", \"bog\": \"boggle\", \"his\": \"his\", \"jos\": \"josh\", \"toe\": \"toe\", \"joe\": \"joe\", \"she\":\"she\"}\n",
    "affix_tree = find_affixes(dictionary)\n",
    "#affix_tree = None\n",
    "board = [['T', 'E', 'S', 'T'],\n",
    "         ['B', 'O', 'H', 'L'],\n",
    "         ['G', 'J', 'I', 'H'],\n",
    "         ['G', 'L', 'E', 'S']]\n",
    "found_words = DFS(board, adj_map, prefix_tree, affix_tree, dictionary)\n",
    "board\n",
    "\n",
    "### TEST BLOCK ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1956aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_dict, prefix_tree = get_dictionary('words_dictionary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ac79e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "affix_tree = find_affixes(en_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "914e239c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary length: 369648 , prefix tree length: 4799 , affix tree length: 654\n"
     ]
    }
   ],
   "source": [
    "print(\"Dictionary length:\", len(en_dict), \", prefix tree length:\", len(prefix_tree), \", affix tree length:\", len(affix_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e405ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "board = create_board(dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ed39fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XED\n",
      "XENYL\n",
      "KELD\n",
      "KED\n",
      "KEA\n",
      "KEX\n",
      "KEN\n",
      "KEND\n",
      "KENYA\n",
      "KENYA\n",
      "KEA\n",
      "KEAS\n",
      "KHA\n",
      "KHALSA\n",
      "KAAS\n",
      "KAE\n",
      "KAE\n",
      "KAL\n",
      "KALE\n",
      "KALEND\n",
      "KALA\n",
      "KALA\n",
      "KALAN\n",
      "KAE\n",
      "KAES\n",
      "HAE\n",
      "HAED\n",
      "HAEN\n",
      "HAE\n",
      "HAK\n",
      "HAKE\n",
      "HAKEA\n",
      "HAL\n",
      "HALE\n",
      "HALED\n",
      "HALA\n",
      "HALAS\n",
      "HALA\n",
      "HALS\n",
      "HALSE\n",
      "HAO\n",
      "HAE\n",
      "HAES\n",
      "HOE\n",
      "HEL\n",
      "HELAS\n",
      "HELD\n",
      "HED\n",
      "HEAL\n",
      "HEALD\n",
      "HEALS\n",
      "HEX\n",
      "HEN\n",
      "HEND\n",
      "HENDLY\n",
      "HEAL\n",
      "HEALD\n",
      "HEALS\n",
      "HEO\n",
      "HEE\n",
      "HEAL\n",
      "HEALED\n",
      "HEALD\n",
      "HEALS\n",
      "HEAL\n",
      "HEALED\n",
      "HEALD\n",
      "HEALS\n",
      "OHED\n",
      "OAK\n",
      "OAKEN\n",
      "DEL\n",
      "DELY\n",
      "DELAY\n",
      "DELAYS\n",
      "DELAY\n",
      "DELAYS\n",
      "DELS\n",
      "DEA\n",
      "DEAL\n",
      "DEALS\n",
      "DEX\n",
      "DEN\n",
      "DENAY\n",
      "DENY\n",
      "DEA\n",
      "DEAS\n",
      "DEAL\n",
      "DEALS\n",
      "ELYSEE\n",
      "ELA\n",
      "ELD\n",
      "ELA\n",
      "ELAN\n",
      "ELAND\n",
      "ELA\n",
      "ELS\n",
      "ELSA\n",
      "ELSE\n",
      "EDNA\n",
      "END\n",
      "ENL\n",
      "ENLAY\n",
      "ENLAY\n",
      "EASY\n",
      "EASE\n",
      "AHO\n",
      "AAS\n",
      "AAL\n",
      "AALS\n",
      "AKE\n",
      "AKELA\n",
      "AKELAS\n",
      "AKELA\n",
      "AKED\n",
      "ALE\n",
      "ALEX\n",
      "ALEN\n",
      "ALEA\n",
      "ALY\n",
      "ALYA\n",
      "ALYA\n",
      "ALN\n",
      "ALA\n",
      "ALAS\n",
      "ALAE\n",
      "ALAE\n",
      "ALAY\n",
      "ALAE\n",
      "ALD\n",
      "ALDEN\n",
      "ALDEA\n",
      "ALA\n",
      "ALAN\n",
      "ALAND\n",
      "ALANE\n",
      "ALAY\n",
      "ALS\n",
      "ALSO\n",
      "AES\n",
      "EASY\n",
      "EASE\n",
      "NAY\n",
      "NAYS\n",
      "NALE\n",
      "NALED\n",
      "NEK\n",
      "NED\n",
      "NEA\n",
      "NEAL\n",
      "NEA\n",
      "NEAL\n",
      "NYALA\n",
      "NYALAS\n",
      "NYALA\n",
      "NYAS\n",
      "NYALA\n",
      "NYALA\n",
      "LEK\n",
      "LEKHA\n",
      "LED\n",
      "LEA\n",
      "LEAH\n",
      "LEAK\n",
      "LEX\n",
      "LEN\n",
      "LEND\n",
      "LENA\n",
      "LEA\n",
      "LEAS\n",
      "LEASE\n",
      "LYS\n",
      "LYSE\n",
      "LYN\n",
      "LYAS\n",
      "LYASE\n",
      "LAS\n",
      "LASE\n",
      "LAEN\n",
      "LAY\n",
      "LAYS\n",
      "LAYNE\n",
      "LAO\n",
      "LAOS\n",
      "LAN\n",
      "LAND\n",
      "LANDE\n",
      "LANE\n",
      "LAY\n",
      "LAYS\n",
      "LAYNE\n",
      "LAH\n",
      "LAEN\n",
      "LAK\n",
      "LAKE\n",
      "LAKED\n",
      "LAKH\n",
      "LAO\n",
      "AAH\n",
      "AAHED\n",
      "AAL\n",
      "AALS\n",
      "ASYLE\n",
      "ASYLA\n",
      "ASYLA\n",
      "ASLAKE\n",
      "ASE\n",
      "ASEA\n",
      "ALE\n",
      "ALEA\n",
      "ALEAK\n",
      "ALEX\n",
      "ALEN\n",
      "ALY\n",
      "ALYA\n",
      "ALN\n",
      "ALD\n",
      "ALDEA\n",
      "ALDEN\n",
      "ALA\n",
      "ALAN\n",
      "ALAND\n",
      "ALANE\n",
      "ALAY\n",
      "ALA\n",
      "ALAHEE\n",
      "ALAE\n",
      "ALAE\n",
      "ALAE\n",
      "ALS\n",
      "ALSO\n",
      "AES\n",
      "AYS\n",
      "AYNE\n",
      "EOS\n",
      "EASY\n",
      "AND\n",
      "ANDE\n",
      "ANLAS\n",
      "ANE\n",
      "ANY\n",
      "AYS\n",
      "AYNE\n",
      "ALE\n",
      "ALEA\n",
      "ALEAK\n",
      "ALEX\n",
      "ALEN\n",
      "ALEA\n",
      "ALY\n",
      "ALYA\n",
      "ALN\n",
      "ALA\n",
      "ALAS\n",
      "ALAE\n",
      "ALAE\n",
      "ALAY\n",
      "ALAE\n",
      "ALD\n",
      "ALDEA\n",
      "ALDEN\n",
      "ALDEA\n",
      "ALA\n",
      "ALAHEE\n",
      "ALAE\n",
      "ALAE\n",
      "ALAE\n",
      "ALS\n",
      "ALSO\n",
      "YAN\n",
      "YALE\n",
      "YALD\n",
      "YAS\n",
      "YALE\n",
      "YALD\n",
      "YAO\n",
      "SAA\n",
      "SAL\n",
      "SALE\n",
      "SALA\n",
      "SALAY\n",
      "SALA\n",
      "SAE\n",
      "SAE\n",
      "SAY\n",
      "SAYA\n",
      "SAYAL\n",
      "SAE\n",
      "SAO\n",
      "SYL\n",
      "SYN\n",
      "SYND\n",
      "SYNE\n",
      "SOE\n",
      "SLED\n",
      "SLY\n",
      "SLA\n",
      "SLAE\n",
      "SLAE\n",
      "SLAY\n",
      "SLAE\n",
      "SLD\n",
      "SLA\n",
      "SLANE\n",
      "SLAY\n",
      "SLA\n",
      "SLAE\n",
      "SLAE\n",
      "SLAKE\n",
      "SLAKED\n",
      "SLAE\n",
      "SEE\n",
      "SEA\n",
      "SEAL\n",
      "SEALED\n",
      "SEALY\n",
      "SEA\n",
      "SEAH\n",
      "SEAK\n",
      "SEAL\n",
      "SEALED\n",
      "SEALY\n",
      "OES\n",
      "OSE\n",
      "35.116235971450806 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "found_words = DFS(board, adj_map, prefix_tree, affix_tree, en_dict)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3de09842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XED\n",
      "XENYL\n",
      "KELD\n",
      "KED\n",
      "KEA\n",
      "KEX\n",
      "KEN\n",
      "KEND\n",
      "KENYA\n",
      "KENYA\n",
      "KEA\n",
      "KEAS\n",
      "KHA\n",
      "KHALSA\n",
      "KAAS\n",
      "KAE\n",
      "KAE\n",
      "KAL\n",
      "KALE\n",
      "KALEND\n",
      "KALA\n",
      "KALA\n",
      "KALAN\n",
      "KAE\n",
      "KAES\n",
      "HAE\n",
      "HAED\n",
      "HAEN\n",
      "HAE\n",
      "HAK\n",
      "HAKE\n",
      "HAKEA\n",
      "HAL\n",
      "HALE\n",
      "HALED\n",
      "HALA\n",
      "HALAS\n",
      "HALA\n",
      "HALS\n",
      "HALSE\n",
      "HAO\n",
      "HAE\n",
      "HAES\n",
      "HOE\n",
      "HEL\n",
      "HELAS\n",
      "HELD\n",
      "HED\n",
      "HEAL\n",
      "HEALD\n",
      "HEALS\n",
      "HEX\n",
      "HEN\n",
      "HEND\n",
      "HENDLY\n",
      "HEAL\n",
      "HEALD\n",
      "HEALS\n",
      "HEO\n",
      "HEE\n",
      "HEAL\n",
      "HEALED\n",
      "HEALD\n",
      "HEALS\n",
      "HEAL\n",
      "HEALED\n",
      "HEALD\n",
      "HEALS\n",
      "OHED\n",
      "OAK\n",
      "OAKEN\n",
      "DEL\n",
      "DELY\n",
      "DELAY\n",
      "DELAYS\n",
      "DELAY\n",
      "DELAYS\n",
      "DELS\n",
      "DEA\n",
      "DEAL\n",
      "DEALS\n",
      "DEX\n",
      "DEN\n",
      "DENAY\n",
      "DENY\n",
      "DEA\n",
      "DEAS\n",
      "DEAL\n",
      "DEALS\n",
      "ELYSEE\n",
      "ELA\n",
      "ELD\n",
      "ELA\n",
      "ELAN\n",
      "ELAND\n",
      "ELA\n",
      "ELS\n",
      "ELSA\n",
      "ELSE\n",
      "EDNA\n",
      "END\n",
      "ENL\n",
      "ENLAY\n",
      "ENLAY\n",
      "EASY\n",
      "EASE\n",
      "AHO\n",
      "AAS\n",
      "AAL\n",
      "AALS\n",
      "AKE\n",
      "AKELA\n",
      "AKELAS\n",
      "AKELA\n",
      "AKED\n",
      "ALE\n",
      "ALEX\n",
      "ALEN\n",
      "ALEA\n",
      "ALY\n",
      "ALYA\n",
      "ALYA\n",
      "ALN\n",
      "ALA\n",
      "ALAS\n",
      "ALAE\n",
      "ALAE\n",
      "ALAY\n",
      "ALAE\n",
      "ALD\n",
      "ALDEN\n",
      "ALDEA\n",
      "ALA\n",
      "ALAN\n",
      "ALAND\n",
      "ALANE\n",
      "ALAY\n",
      "ALS\n",
      "ALSO\n",
      "AES\n",
      "EASY\n",
      "EASE\n",
      "NAY\n",
      "NAYS\n",
      "NALE\n",
      "NALED\n",
      "NEK\n",
      "NED\n",
      "NEA\n",
      "NEAL\n",
      "NEA\n",
      "NEAL\n",
      "NYALA\n",
      "NYALAS\n",
      "NYALA\n",
      "NYAS\n",
      "NYALA\n",
      "NYALA\n",
      "LEK\n",
      "LEKHA\n",
      "LED\n",
      "LEA\n",
      "LEAH\n",
      "LEAK\n",
      "LEX\n",
      "LEN\n",
      "LEND\n",
      "LENA\n",
      "LEA\n",
      "LEAS\n",
      "LEASE\n",
      "LYS\n",
      "LYSE\n",
      "LYN\n",
      "LYAS\n",
      "LYASE\n",
      "LAS\n",
      "LASE\n",
      "LAEN\n",
      "LAY\n",
      "LAYS\n",
      "LAYNE\n",
      "LAO\n",
      "LAOS\n",
      "LAN\n",
      "LAND\n",
      "LANDE\n",
      "LANE\n",
      "LAY\n",
      "LAYS\n",
      "LAYNE\n",
      "LAH\n",
      "LAEN\n",
      "LAK\n",
      "LAKE\n",
      "LAKED\n",
      "LAKH\n",
      "LAO\n",
      "AAH\n",
      "AAHED\n",
      "AAL\n",
      "AALS\n",
      "ASYLE\n",
      "ASYLA\n",
      "ASYLA\n",
      "ASLAKE\n",
      "ASE\n",
      "ASEA\n",
      "ALE\n",
      "ALEA\n",
      "ALEAK\n",
      "ALEX\n",
      "ALEN\n",
      "ALY\n",
      "ALYA\n",
      "ALN\n",
      "ALD\n",
      "ALDEA\n",
      "ALDEN\n",
      "ALA\n",
      "ALAN\n",
      "ALAND\n",
      "ALANE\n",
      "ALAY\n",
      "ALA\n",
      "ALAHEE\n",
      "ALAE\n",
      "ALAE\n",
      "ALAE\n",
      "ALS\n",
      "ALSO\n",
      "AES\n",
      "AYS\n",
      "AYNE\n",
      "EOS\n",
      "EASY\n",
      "AND\n",
      "ANDE\n",
      "ANLAS\n",
      "ANE\n",
      "ANY\n",
      "AYS\n",
      "AYNE\n",
      "ALE\n",
      "ALEA\n",
      "ALEAK\n",
      "ALEX\n",
      "ALEN\n",
      "ALEA\n",
      "ALY\n",
      "ALYA\n",
      "ALN\n",
      "ALA\n",
      "ALAS\n",
      "ALAE\n",
      "ALAE\n",
      "ALAY\n",
      "ALAE\n",
      "ALD\n",
      "ALDEA\n",
      "ALDEN\n",
      "ALDEA\n",
      "ALA\n",
      "ALAHEE\n",
      "ALAE\n",
      "ALAE\n",
      "ALAE\n",
      "ALS\n",
      "ALSO\n",
      "YAN\n",
      "YALE\n",
      "YALD\n",
      "YAS\n",
      "YALE\n",
      "YALD\n",
      "YAO\n",
      "SAA\n",
      "SAL\n",
      "SALE\n",
      "SALA\n",
      "SALAY\n",
      "SALA\n",
      "SAE\n",
      "SAE\n",
      "SAY\n",
      "SAYA\n",
      "SAYAL\n",
      "SAE\n",
      "SAO\n",
      "SYL\n",
      "SYN\n",
      "SYND\n",
      "SYNE\n",
      "SOE\n",
      "SLED\n",
      "SLY\n",
      "SLA\n",
      "SLAE\n",
      "SLAE\n",
      "SLAY\n",
      "SLAE\n",
      "SLD\n",
      "SLA\n",
      "SLANE\n",
      "SLAY\n",
      "SLA\n",
      "SLAE\n",
      "SLAE\n",
      "SLAKE\n",
      "SLAKED\n",
      "SLAE\n",
      "SEE\n",
      "SEA\n",
      "SEAL\n",
      "SEALED\n",
      "SEALY\n",
      "SEA\n",
      "SEAH\n",
      "SEAK\n",
      "SEAL\n",
      "SEALED\n",
      "SEALY\n",
      "OES\n",
      "OSE\n",
      "15.413065195083618 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "found_words = DFS(board, adj_map, prefix_tree, None, en_dict)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cf89b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_dice = [['l', 'i', 'õ', 's', 'j', 'f'],\n",
    "           ['i', 'õ', 'a', 'd', 'a', 'g'],\n",
    "           ['p', 'a', 't', 's', 'b', 'u'],\n",
    "           ['m', 'k', 's', 'ü', 't', 'p'],\n",
    "           ['d', 'v', 'u', 'l', 'e', 's'],\n",
    "           ['n', 'm', 'o', 'a', 'k', 'u'],\n",
    "           ['e', 'r', 'i', 'k', 's', 'e'],\n",
    "           ['g', 'n', 'h', 'ü', 'm', 'a'],\n",
    "           ['š', 'j', 'v', 'J', 's', 'e'],\n",
    "           ['a', 'd', 'i', 'u', 'o', 't'],\n",
    "           ['ä', 'a', 'k', 'i', 'h', 't'],\n",
    "           ['j', 'e', 'n', 'i', 'g', 'k'],\n",
    "           ['a', 'ö', 'e', 'ä', 't', 'p'],\n",
    "           ['l', 'e', 'n', 'a', 'u', 'r'],\n",
    "           ['m', 'b', 'i', 'n', 'l', 'h'],\n",
    "           ['o', 'e', 'r', 'a', 'v', 'p']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2efbcf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_dict, et_prefix_tree = get_dictionary('lemmad2013.txt')\n",
    "et_affix_tree = find_affixes(et_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "49d53007",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_board = create_board(et_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ddd3202c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uig\n",
      "uig\n",
      "uih\n",
      "viki\n",
      "viki\n",
      "viig\n",
      "viigi\n",
      "viik\n",
      "viiki\n",
      "viu\n",
      "viht\n",
      "vihk\n",
      "vihik\n",
      "vihk\n",
      "vuih\n",
      "viu\n",
      "viik\n",
      "viiki\n",
      "viig\n",
      "viigi\n",
      "viir\n",
      "viki\n",
      "viki\n",
      "rivi\n",
      "rivik\n",
      "riiu\n",
      "riigi\n",
      "riiv\n",
      "riik\n",
      "riht\n",
      "rihti\n",
      "rihk\n",
      "rihk\n",
      "igi\n",
      "igi\n",
      "igi\n",
      "igi\n",
      "irv\n",
      "irvi\n",
      "irvik\n",
      "ihk\n",
      "ihk\n",
      "lik\n",
      "liht\n",
      "lihk\n",
      "lihk\n",
      "kivi\n",
      "kii\n",
      "kiiv\n",
      "kih\n",
      "kiht\n",
      "kihi\n",
      "kihik\n",
      "kihl\n",
      "kihk\n",
      "kii\n",
      "kiiv\n",
      "kiir\n",
      "kivi\n",
      "hiv\n",
      "hii\n",
      "hiiu\n",
      "higi\n",
      "higi\n",
      "hirv\n",
      "ihk\n",
      "ihii\n",
      "ihk\n",
      "itk\n",
      "itk\n",
      "igi\n",
      "igi\n",
      "pigi\n",
      "pigi\n",
      "piki\n",
      "piki\n",
      "pikt\n",
      "ptk\n",
      "ptk\n",
      "tihk\n",
      "tihi\n",
      "tihk\n",
      "kih\n",
      "kiht\n",
      "kihk\n",
      "kihi\n",
      "kihik\n",
      "kihl\n",
      "13.578789234161377 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "found_words = DFS(et_board, adj_map, et_prefix_tree, et_affix_tree, et_dict)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3e40ee02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uig\n",
      "uig\n",
      "uih\n",
      "viki\n",
      "viki\n",
      "viig\n",
      "viigi\n",
      "viik\n",
      "viiki\n",
      "viu\n",
      "viht\n",
      "vihk\n",
      "vihik\n",
      "vihk\n",
      "vuih\n",
      "viu\n",
      "viik\n",
      "viiki\n",
      "viig\n",
      "viigi\n",
      "viir\n",
      "viki\n",
      "viki\n",
      "rivi\n",
      "rivik\n",
      "riiu\n",
      "riigi\n",
      "riiv\n",
      "riik\n",
      "riht\n",
      "rihti\n",
      "rihk\n",
      "rihk\n",
      "igi\n",
      "igi\n",
      "igi\n",
      "igi\n",
      "irv\n",
      "irvi\n",
      "irvik\n",
      "ihk\n",
      "ihk\n",
      "lik\n",
      "liht\n",
      "lihk\n",
      "lihk\n",
      "kivi\n",
      "kii\n",
      "kiiv\n",
      "kih\n",
      "kiht\n",
      "kihi\n",
      "kihik\n",
      "kihl\n",
      "kihk\n",
      "kii\n",
      "kiiv\n",
      "kiir\n",
      "kivi\n",
      "hiv\n",
      "hii\n",
      "hiiu\n",
      "higi\n",
      "higi\n",
      "hirv\n",
      "ihk\n",
      "ihii\n",
      "ihk\n",
      "itk\n",
      "itk\n",
      "igi\n",
      "igi\n",
      "pigi\n",
      "pigi\n",
      "piki\n",
      "piki\n",
      "pikt\n",
      "ptk\n",
      "ptk\n",
      "tihk\n",
      "tihi\n",
      "tihk\n",
      "kih\n",
      "kiht\n",
      "kihk\n",
      "kihi\n",
      "kihik\n",
      "kihl\n",
      "8.363850355148315 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "found_words = DFS(et_board, adj_map, et_prefix_tree, None, et_dict)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c5bb15aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "587"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(et_affix_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb7136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
